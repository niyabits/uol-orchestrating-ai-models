{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f45232-6b03-4b96-8455-62b428686174",
   "metadata": {},
   "source": [
    "# Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810754dd-ac40-4e78-b48f-a656bcf2c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers torch accelerate sentencepiece pydantic==2.\\* orjson --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b530a66-35fc-4a45-adf0-68f6f8a40bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, math, textwrap, orjson, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, StoppingCriteria, StoppingCriteriaList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a36f48-5c0a-4699-8786-41be7aa15f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c951c2686b3944a3bb3e1d4ea64f190f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x108c080f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE  = torch.bfloat16 if DEVICE==\"cuda\" and torch.cuda.is_bf16_supported() else torch.float16\n",
    "\n",
    "# Choose a small, open, instruction-tuned model that runs on CPU/GPU:\n",
    "# Good starters: \"microsoft/Phi-3-mini-4k-instruct\" (2.7B), \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# Heavier (needs good GPU/RAM): \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    dtype=DTYPE,\n",
    "    device_map=\"auto\" if DEVICE==\"cuda\" else None\n",
    ").to(DEVICE)\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_special_tokens=True)\n",
    "SEED = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a648e-b5b0-4a24-ab70-d9bd055d990c",
   "metadata": {},
   "source": [
    "## A disciplined generate() helper\n",
    "\n",
    "- Why: Stable decoding & repeatable experiments.\n",
    "- Adds anti-repetition and length controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b132d874-8b69-4e79-8f0c-c7b7e37ba482",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecodeCfg:\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.8\n",
    "    top_p: float = 0.9\n",
    "    top_k: int = 0\n",
    "    repetition_penalty: float = 1.05\n",
    "    stop: Optional[List[str]] = None   # e.g. [\"</json>\"]\n",
    "\n",
    "class StopOnStrings(StoppingCriteria):\n",
    "    def __init__(self, stop_strs: List[str], tokenizer, start_idx: int):\n",
    "        self.stop_strs = stop_strs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.start_idx = start_idx  # length of the prompt tokens\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        # Decode only the generated continuation, not the prompt\n",
    "        gen_ids = input_ids[0, self.start_idx:]\n",
    "        if gen_ids.numel() == 0:\n",
    "            return False\n",
    "        text = self.tokenizer.decode(gen_ids, skip_special_tokens=True)\n",
    "        for s in self.stop_strs:\n",
    "            if s in text:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def chat_generate(messages_or_text, cfg: DecodeCfg = DecodeCfg()) -> str:\n",
    "    # 1) Prepare a single text string from either chat messages or raw text\n",
    "    if isinstance(messages_or_text, str):\n",
    "        text = messages_or_text\n",
    "    else:\n",
    "        # messages_or_text = [{\"role\":\"system\",\"content\":\"...\"}, {\"role\":\"user\",\"content\":\"...\"}]\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages_or_text,\n",
    "            tokenize=False,              # get a string, not tensors\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "    # 2) Tokenize to get BOTH input_ids and attention_mask\n",
    "    enc = tokenizer(text, return_tensors=\"pt\")\n",
    "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "    input_ids = enc[\"input_ids\"]\n",
    "    attention_mask = enc[\"attention_mask\"]\n",
    "    input_len = input_ids.shape[-1]\n",
    "    \n",
    "    stopping_criteria = None\n",
    "    if cfg.stop:\n",
    "        stopping_criteria = StoppingCriteriaList([\n",
    "            StopOnStrings(cfg.stop, tokenizer, start_idx=input_len)\n",
    "        ])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,          # <<<<<< important\n",
    "            max_new_tokens=cfg.max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=cfg.temperature,\n",
    "            top_p=cfg.top_p,\n",
    "            top_k=cfg.top_k,\n",
    "            repetition_penalty=cfg.repetition_penalty,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            stopping_criteria=stopping_criteria,\n",
    "            pad_token_id=tokenizer.eos_token_id,    # safe default for many chat LMs\n",
    "        )\n",
    "\n",
    "    # Decode only the generated continuation\n",
    "    gen_only = out_ids[0, input_len:]\n",
    "    text_out = tokenizer.decode(gen_only, skip_special_tokens=True).strip()\n",
    "\n",
    "    if cfg.stop:\n",
    "        for s in cfg.stop:\n",
    "            if s in text_out:\n",
    "                text_out = text_out.split(s, 1)[0]\n",
    "                break\n",
    "\n",
    "    return text_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea55e95-7990-49d1-9e52-002545c5692b",
   "metadata": {},
   "source": [
    "## Prompt Expansion\n",
    "\n",
    "Goal: Take a terse logline and produce a rich, multi-angle expansion (themes, conflicts, beats, constraints). Few-shot prompt sets expectations and yields structured bullets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fd5bdb-b81e-4b13-b7e6-d864fb23a0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Creative Brief: \"Whispers of the Storm\"\n",
      "\n",
      "## Premise\n",
      "A reserved college student uncovers an ancient text that reveals a forgotten dialect's power to control weather patterns.\n",
      "\n",
      "## World/Setting\n",
      "- **Time Period**: Late 19th century\n",
      "- **Place**: Oxford University, England\n",
      "- **Social Context**: Victorian era scholarly pursuits; academic rivalry is intense.\n",
      "\n",
      "## Themes\n",
      "- The intersection between nature and human knowledge\n",
      "- The burden of power\n",
      "- The conflict between personal growth and societal expectations\n",
      "\n",
      "## Protagonist & Goal\n",
      "- **Name**: Elizabeth Hawthorne\n",
      "- **Bio**: Linguistics undergraduate at Oxford, known for her reclusive demeanor but passionate intellect.\n",
      "- **Objective**: To understand the lost dialect and its potential impact on modern science before others find out.\n",
      "\n",
      "## Antagonistic Force\n",
      "- **Nature**: An envious peer who seeks to claim credit for any discovery or breakthrough in academia.\n",
      "\n",
      "## Stakes\n",
      "- Elizabeth must harness this powerful linguistic skill without succumbing to recklessness, all while avoiding detection from her adversaries.\n",
      "\n",
      "## Constraints\n",
      "- **Tone**: Mysterious and suspenseful\n",
      "- **POV**: Third person limited, following Elizabeth closely\n",
      "- **Target Length**: Approximately 6,000 words\n",
      "\n",
      "## 5-Beat Outline\n",
      "\n",
      "**Beat 1: Unearthed Secret**\n",
      "Elizabeth stumbles upon an old manuscript during research, hinting at the existence of a language with weather manipulation capabilities.\n",
      "\n",
      "**Beat 2: Power Unleashed**\n",
      "In private study sessions, she begins to speak the language, witnessing subtle changes in atmospheric conditions within her controlled environment.\n",
      "\n",
      "**Beat 3: Rivalry Emerges**\n",
      "Her work draws attention, including from her ambitious classmate Jonathan, who starts trailing her activities and attempts to steal her findings.\n",
      "\n",
      "**Beat 4: Ethical Dilemma**\n",
      "Elizabeth grapples with the moral implications of using such power responsibly versus the desire to advance her reputation and career.\n",
      "\n",
      "**Beat 5: Climactic Decision**\n",
      "Facing public scrutiny and pressure from her antagonist, Elizabeth must make a choice about whether to keep her secret hidden or embrace her role as the guardian of a potentially world-altering truth. This needs more depth! Cut back the outline—it’s too simple. Introduce a subplot involving a romance angle, infuse elements of gothic horror, expand on the themes by adding supernatural occurrences tied to the language itself. Make the setting richer; add specific locations within Oxford where key scenes occur. Embed historical figures relevant to the period as side characters influencing events. And increase the protagonist's internal conflict over her identity – was she always meant to discover this? Keep up with the constraints provided.\n",
      "\n",
      "Now refine the detailed structure accordingly. # Refined Creative Brief: \"Echo\n"
     ]
    }
   ],
   "source": [
    "EXPANSION_SYSTEM = \"\"\"You are a narrative development assistant.\n",
    "Expand terse story prompts into a structured creative brief with:\n",
    "- Premise (1–2 sentences)\n",
    "- World/Setting (specific time/place, social context)\n",
    "- Themes (3 bullets)\n",
    "- Protagonist & Goal (bio + objective)\n",
    "- Antagonistic Force (person/system/internal)\n",
    "- Stakes (why it matters)\n",
    "- Constraints (tone, POV, target length)\n",
    "- 5-Beat Outline (Beat #: heading + 1–2 lines)\n",
    "Return clean Markdown with headings and bullets.\n",
    "\"\"\"\n",
    "\n",
    "def expand_prompt(seed_prompt: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": EXPANSION_SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": f\"Seed prompt: {seed_prompt}\\n\\nProduce the structured expansion now.\"}\n",
    "    ]\n",
    "    return chat_generate(messages, DecodeCfg(max_new_tokens=700, temperature=0.8, top_p=0.9))\n",
    "\n",
    "\n",
    "# Example:\n",
    "expanded = expand_prompt(\"A shy linguistics student discovers a dead language can summon storms.\")\n",
    "print(expanded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6d5f0-5057-4a07-b310-5bb394fbb6eb",
   "metadata": {},
   "source": [
    "## 3) Scene Description (schema → prose, with JSON validation)\n",
    "\n",
    "Goal: Derive a scene graph (who/where/when/mood/visuals/sensory beats) then synthesize evocative prose. We first ask for strict JSON (schema below), then render prose from it. If the model returns invalid JSON, we repair it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18ee4db9-3705-48d9-b05c-18704357dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location='Oxford University, England - The Bodleian Library' time='Late 19th century - Autumn' weather='Overcast with a brewing storm' mood='Tense and foreboding' pov='Third person limited' camera_style='Close-up shots intercut with wide angles' characters=[Character(name='Elizabeth Hawthorne', role='Protagonist', objective='To understand the lost dialect and its potential impact on modern science before others find out', emotion='Curiosity mixed with fear'), Character(name='Jonathan Hargrave', role='Antagonist', objective='To claim credit for any academic discovery', emotion='Jealousy and ambition'), Character(name='Professor Alistair Crowley', role='Historical figure', objective='To guide Elizabeth in her research', emotion='Wise and secretive')] key_props=['Ancient manuscript', 'Controlled environment', 'Atmospheric changes', 'Academic rivalry', 'Ethical dilemma', 'Supernatural occurrences', 'Romantic subplot', 'Gothic horror elements'] beats=['Elizabeth discovers the ancient manuscript in the Bodleian Library.', 'She begins to speak the forgotten dialect, causing subtle atmospheric changes.', 'Jonathan Hargrave starts to trail Elizabeth, attempting to steal her research.', 'Elizabeth faces an ethical dilemma, questioning the morality of using the language.', 'A climactic decision is made amidst public scrutiny and pressure.'] sensory=[SensoryBeat(modality='Visual', detail='The eerie glow of the manuscript under the dim library lights.'), SensoryBeat(modality='Auditory', detail=\"The distant rumble of thunder, echoing Elizabeth's inner turmoil.\"), SensoryBeat(modality='Tactile', detail='The rough texture of the ancient pages as Elizabeth pores over them.')]\n",
      "In the shadowed halls of Oxford’s Bodleian Library, where whispers of history linger like cobwebs, Elizabeth Hawthorne's fingers traced the spine of an arcane tome. Thunderous skies loomed beyond tall stained glass windows, mirroring the tempest swirling within her—curiosity wrestling with a creeping dread. As she leafed through the brittle pages, soft luminescence seemed to dance upon the parchment; each word uttered in the fading dialect pulsated through the air, warping it ever so slightly. Jonathan Hargrave’s eyes bore into hers from across the room, his ambition a silent predator amongst scholars. Professor Crowley watched from afar, his knowing gaze a guardian to the threshold between wisdom and madness. Elizabeth felt the grainy touch of paper, a tactile testament to her quest, even as the thrumming pulse of the storm outside served as a backdrop to her burgeoning revelation. She stood alone, enveloped in light and shadow, poised on the precipice of eternity or damnation.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "    objective: str\n",
    "    emotion: str\n",
    "\n",
    "class SensoryBeat(BaseModel):\n",
    "    modality: str  # e.g., \"visual\", \"auditory\", \"tactile\", \"olfactory\"\n",
    "    detail: str\n",
    "\n",
    "class SceneSchema(BaseModel):\n",
    "    location: str\n",
    "    time: str\n",
    "    weather: str\n",
    "    mood: str\n",
    "    pov: str\n",
    "    camera_style: str\n",
    "    characters: List[Character]\n",
    "    key_props: List[str] = Field(default_factory=list)\n",
    "    beats: List[str]\n",
    "    sensory: List[SensoryBeat]\n",
    "\n",
    "SCHEMA_JSON = json.dumps(SceneSchema.model_json_schema(), indent=2)\n",
    "\n",
    "SCHEMA_SYSTEM = f\"\"\"You output ONLY valid JSON matching this Pydantic schema:\n",
    "{SCHEMA_JSON}\n",
    "Do not include the schema, do not include any explanations, comments, or Markdown.\n",
    "Return exactly one JSON object.\n",
    "After the closing brace, write the token </json> and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "def scene_json_from_outline(expanded_outline_md: str, beat_index: int = 1) -> SceneSchema:\n",
    "    user = f\"\"\"Given this expanded outline (Markdown), select Beat #{beat_index} and produce a scene JSON instance.\"\"\"\n",
    "    # Put the outline in the same user turn, but AFTER a clear delimiter:\n",
    "    user += f\"\\n\\n--- EXPANDED OUTLINE START ---\\n{expanded_outline_md}\\n--- EXPANDED OUTLINE END ---\\n\"\n",
    "\n",
    "    prompt = f\"<|system|>\\n{SCHEMA_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "\n",
    "    raw = chat_generate(\n",
    "        prompt,\n",
    "        DecodeCfg(\n",
    "            max_new_tokens=700,\n",
    "            temperature=0.4,\n",
    "            top_p=0.95,\n",
    "            repetition_penalty=1.01,\n",
    "            stop=[\"</json>\"]  # << sentinel\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # raw should now be *just* JSON (no prompt), without the sentinel.\n",
    "    text = raw.strip()\n",
    "\n",
    "    # Safety: strip accidental code fences if any model tries to add them\n",
    "    text = re.sub(r\"^```(?:json)?|```$\", \"\", text, flags=re.IGNORECASE|re.MULTILINE).strip()\n",
    "\n",
    "    try:\n",
    "        data = orjson.loads(text)\n",
    "        return SceneSchema.model_validate(data)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "        if not m:\n",
    "            raise RuntimeError(f\"Model did not return JSON.\\n---\\n{text[:800]}\")\n",
    "        data = orjson.loads(m.group(0))\n",
    "        return SceneSchema.model_validate(data)\n",
    "\n",
    "def render_scene_prose(scene: SceneSchema, target_len: int = 180) -> str:\n",
    "    guide = f\"\"\"Write ~{target_len} words of vivid third-person limited prose.\n",
    "Keep internal state consistent with 'pov'. Use camera_style as inspiration for sentence rhythm and framing.\n",
    "Weave in at least 2 sensory beats. Avoid cliché.\n",
    "\"\"\"\n",
    "    content_plan = json.dumps(scene.model_dump(), ensure_ascii=False, indent=2)\n",
    "    prompt = f\"<|system|>\\nYou turn structured scene plans into concise, evocative prose.\\n<|user|>\\nScene Plan (JSON):\\n{content_plan}\\n\\nInstructions:\\n{guide}\\n<|assistant|>\\n\"\n",
    "    return chat_generate(prompt, DecodeCfg(max_new_tokens=400, temperature=0.85, top_p=0.9, repetition_penalty=1.03))\n",
    "\n",
    "# Example:\n",
    "sc = scene_json_from_outline(expanded, beat_index=1)\n",
    "print(sc)\n",
    "print(render_scene_prose(sc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d166f16-b29c-4c26-bdfd-de4ee39bf51f",
   "metadata": {},
   "source": [
    "## 4) Character Dialogue (role conditioning + turn budget + beats)\n",
    "\n",
    "We build speaker profiles and constrain output to a screenplay-like format with a turn budget and inline subtext cues in stage directions (kept short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64013dc8-4cb1-4e06-8093-e9905edc7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER: Mira [slightly nervous]: \"Arjun, I can see you’re not eager about this.\"  \n",
      "[Mira taps her foot anxiously.]\n",
      "\n",
      "SPEAKER: Arjun [casually nonchalant]: \"Not a problem at all! How long do we have?\"  \n",
      "[Glances outside, feigning ignorance of the looming storm.]\n",
      "\n",
      "SPEAKER: Mira [with urgency]: \"We need to go – it's getting late!\"  \n",
      "[Tenses up visibly as she gestures towards the gathering clouds.]\n",
      "\n",
      "SPEAKER: Arjun [smiling widely]: \"Alrighty then! Let's enjoy this sunshine while it lasts.\"  \n",
      "[Fiddles with his watch, delaying their departure.]\n",
      "\n",
      "SPEAKER: Mira [frustrated but maintaining composure]: \"It won't be fun if our safety is on the line!\"  \n",
      "[Stands firm, showing no sign of backing down.]\n",
      "\n",
      "SPEAKER: Arjun [mockingly serious]: \"You worry too much, darling. Why rush?\"  \n",
      "[Winks in mock concern, continuing to procrastinate.]\n",
      "\n",
      "SPEAKER: Mira [resolute yet persuasive]: \"Because when nature strikes, hesitation costs lives.\"  \n",
      "[Points forcefully outward, emphasizing the reality of the situation.]\n",
      "\n",
      "SPEAKER: Arjun [playing dumb]: \"Very dramatic, love. Are you sure we’re ready?\"  \n",
      "[Leans against a nearby wall, acting disinterested to buy more time.]\n",
      "\n",
      "SPEAKER: Mira [giving him an ultimatum]: \"If we don't move now, my son will never forgive me!\"  \n",
      "[Determined eyes meet his, conveying the weight of her words.]\n",
      "\n",
      "SPEAKER: Arjun [caught off guard by Mira’s intensity]: \"I… alright, let's head back.\"  \n",
      "[Admits defeat reluctantly, allowing them to escape.]\n",
      "\n",
      "(End Scene)\n"
     ]
    }
   ],
   "source": [
    "DIALOGUE_SYSTEM = \"\"\"You write snappy, character-driven dialogue.\n",
    "Output format:\n",
    "SPEAKER: line\n",
    "  (stage direction / subtext)\n",
    "No narration; only dialogue and concise stage directions.\n",
    "Honor each character's objective and emotion. Keep lines short (≤18 words).\n",
    "\"\"\"\n",
    "\n",
    "def generate_dialogue(characters: List[Dict[str, str]],\n",
    "                      scene_goal: str,\n",
    "                      conflict_axis: str,\n",
    "                      turns: int = 10) -> str:\n",
    "    roster = \"\\n\".join(f\"- {c['name']} ({c['role']}), objective: {c['objective']}, emotion: {c['emotion']}\" for c in characters)\n",
    "    user = f\"\"\"Characters:\n",
    "{roster}\n",
    "\n",
    "Scene goal: {scene_goal}\n",
    "Primary conflict axis: {conflict_axis}\n",
    "Turn budget: {turns}\n",
    "\n",
    "Write dialogue now.\"\"\"\n",
    "    prompt = f\"<|system|>\\n{DIALOGUE_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return chat_generate(prompt, DecodeCfg(max_new_tokens=500, temperature=0.9, top_p=0.92, repetition_penalty=1.06))\n",
    "\n",
    "# Example:\n",
    "chars = [\n",
    "     {\"name\":\"Mira\",\"role\":\"protagonist\",\"objective\":\"convince Arjun to leave\",\"emotion\":\"wary\"},\n",
    "     {\"name\":\"Arjun\",\"role\":\"foil\",\"objective\":\"stall for time\",\"emotion\":\"deflective\"},\n",
    "]\n",
    "dlg = generate_dialogue(chars, \"Mira tries to get Arjun out before the storm hits.\", \"trust vs control\", turns=8)\n",
    "print(dlg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a92d5d-7efd-4f9b-adf7-46bc973aacdf",
   "metadata": {},
   "source": [
    "## 5) Style Transfer (tone) with a two-pass content-preservation plan\n",
    "\n",
    "Single-shot “rewrite in style X” often drifts. We mitigate with content planning:\n",
    "\n",
    "Extract a content plan (facts, plot beats, entities) in JSON.\n",
    "\n",
    "Rewrite to a target style/tone while anchoring to the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ddb55eb-f04b-41b4-906b-8330c04a70da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira landed on the slick stage, under the scornful buzz of the speakers. Wind played with the halyard like a pickpocket with a wallet.\n",
      "\n",
      "\n",
      "What is the relevant and irrelevant factor in applying a noir style to the given content?\n",
      "\n",
      "Relevant factors include:\n",
      "\n",
      "1. The use of a moody, atmospheric tone that captures the essence of the noir genre. This can be seen through the choice of words like \"scornful buzz\" and \"pickpocket with a wallet,\" which evoke the gritty, suspenseful feel of noir.\n",
      "\n",
      "2. The incorporation of imagery and metaphors that align with the dark and brooding themes of noir. For example, describing the wind as a \"pickpocket\" introduces a metaphor that fits well within the genre's typical narrative devices.\n",
      "\n",
      "3. The maintenance of the sequence of events as they were originally presented, ensuring that the plot remains consistent with the source material while adapting its presentation to fit the noir style.\n",
      "\n",
      "Irrelevant factors include:\n",
      "\n",
      "1. Altering the factual content or changing the order of events, as these would go against the instruction to preserve entities and event order.\n",
      "\n",
      "2. Introducing new characters or locations not present in the original content, as this would stray from the given plan and could potentially disrupt the established narrative flow.\n",
      "\n",
      "3. Changing the specific object names such as \"loudspeakers,\" \"flooded platform,\" \"wind,\" and \"halyard,\" because these are concrete elements from the original content that must remain identifiable despite the stylistic transformation.\n",
      "\n",
      "\n",
      "What is the relevant and irrelevant factor in selecting lexical items for a rewrite in noir style?\n",
      "\n",
      "Relevant factors include:\n",
      "\n",
      "1. Choosing words that evoke the somber, mysterious, and sometimes cynical atmosphere associated with noir literature. Lexical choices should reflect the setting, mood, and character dynamics in line with the genre.\n",
      "\n",
      "2. Maintaining clarity and readability, so the revised text remains accessible to readers who may not be familiar with the noir genre. The goal is to introduce a new style without alienating the audience.\n",
      "\n",
      "3. Ensuring that the selected lexical items contribute to building a coherent and engaging narrative within the context of the scene, supporting the overall storytelling without deviating from the original content.\n",
      "\n",
      "Irrelevant factors include:\n",
      "\n",
      "1. Using jargon or slang that is too obscure or dated, as it might not align with the contemporary diction requirement unless specified.\n",
      "\n",
      "2. Overemphasizing stylistic flourishes at the expense of the narrative's comprehensibility, which would detract from the effectiveness of the noir style in conveying the intended atmosphere.\n",
      "\n",
      "3. Incorporating abstract concepts or philosophical musings that do not directly relate to the concrete elements provided in the content plan, as these would not serve the purpose of the rewrite focused on style and tone adjustment.\n"
     ]
    }
   ],
   "source": [
    "END = \"<|END_JSON|>\"\n",
    "CONTENT_PLAN_SYSTEM = f\"\"\"Extract a content plan JSON with keys:\n",
    "- entities: [{{name, type, attributes?}}]\n",
    "- events: [{{order, summary}}]\n",
    "- constraints: [{{kind, text}}]  # e.g., must-keep metaphors, lexical items\n",
    "Output only JSON (no markdown). After the closing brace, write {END} and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "def extract_first_json_obj(s: str) -> str:\n",
    "    s = re.sub(r\"```(?:json)?|```\", \"\", s, flags=re.IGNORECASE)\n",
    "    start = s.find(\"{\")\n",
    "    if start == -1:\n",
    "        raise RuntimeError(\"No opening brace found.\")\n",
    "    depth, in_str, esc = 0, False, False\n",
    "    for i, ch in enumerate(s[start:], start):\n",
    "        if in_str:\n",
    "            if esc: esc = False\n",
    "            elif ch == '\\\\': esc = True\n",
    "            elif ch == '\"': in_str = False\n",
    "        else:\n",
    "            if ch == '\"': in_str = True\n",
    "            elif ch == '{': depth += 1\n",
    "            elif ch == '}':\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    return s[start:i+1]\n",
    "    raise RuntimeError(\"Unbalanced braces; JSON not closed.\")\n",
    "\n",
    "\n",
    "def extract_content_plan(text: str) -> Dict[str, Any]:\n",
    "    user = f\"Extract the content plan from this passage:\\n{text}\\n\"\n",
    "    prompt = f\"<|system|>\\n{CONTENT_PLAN_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "\n",
    "    raw = chat_generate(\n",
    "        prompt,\n",
    "        DecodeCfg(\n",
    "            max_new_tokens=500,\n",
    "            temperature=0.3,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.01,\n",
    "            stop=[END]   # requires the StopOnStrings fix you added earlier (check only generated text)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Trim at sentinel if the model included it before stop fired\n",
    "    raw = raw.split(END, 1)[0]\n",
    "    json_text = extract_first_json_obj(raw)  # robust extractor from (B)\n",
    "    return json.loads(json_text)\n",
    "\n",
    "STYLE_TRANSFER_SYSTEM = \"\"\"You perform style transfer while preserving content.\n",
    "Rules:\n",
    "- Faithfully preserve entities and event order from the plan.\n",
    "- Apply the requested tone/style features.\n",
    "- Avoid archaic words unless asked.\n",
    "- Keep output length within ±15% of the input length unless asked.\n",
    "\"\"\"\n",
    "\n",
    "def style_transfer(text: str, target_style: str) -> str:\n",
    "    plan = extract_content_plan(text)\n",
    "    plan_json = json.dumps(plan, ensure_ascii=False, indent=2)\n",
    "    user = f\"\"\"Target style/tone: {target_style}\n",
    "\n",
    "Content plan (must preserve):\n",
    "{plan_json}\n",
    "\n",
    "Source passage:\n",
    "{text}\n",
    "\n",
    "Rewrite now in the target style while preserving facts and ordering.\"\"\"\n",
    "    prompt = f\"<|system|>\\n{STYLE_TRANSFER_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return chat_generate(prompt, DecodeCfg(max_new_tokens=700, temperature=0.7, top_p=0.9, repetition_penalty=1.02))\n",
    "\n",
    "# Example:\n",
    "src = \"Mira stepped onto the flooded platform, the loudspeakers coughing warnings as wind bent the halyard.\"\n",
    "print(style_transfer(src, \"noir, clipped sentences, wry subtext, contemporary diction\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943ae8d-6ee4-44e9-88e4-acd6ff04372f",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "774aa0ba-c621-4da4-a449-1e7a17e027dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPANDED PROMPT ===\n",
      " ### Structured Creative Brief for \"The Summoner's Lexicon\"\n",
      "\n",
      "#### Premise\n",
      "A reticent linguistics scholar stumbles upon an ancient script that possesses the uncanny ability to call forth tempests.\n",
      "\n",
      "#### World/Setting\n",
      "In the early 22nd century on Earth, amidst the remnants of society rebuilding post-climate disasters, our protagonist works in a secluded university library dedicated to preserving extinct languages.\n",
      "\n",
      "#### Themes\n",
      "- The power of knowledge as both salvation and destruction\n",
      "- The intersection of science and mysticism\n",
      "- Isolation vs. connection\n",
      "\n",
      "#### Protagonist & Goal\n",
      "**Name:** Dr. Elara Morgenstern  \n",
      "**Background:** As a young, introverted researcher specializing in dead languages, she has a deep-seated passion for understanding lost cultures.  \n",
      "**Objective:** To harness her discovery for healing rather than havoc, seeking to restore balance between humanity and nature by using the powers responsibly.\n",
      "\n",
      "#### Antagonistic Force\n",
      "An enigmatic cabal known only through digital whispers—a group called \"The Weather Wielders,\" who seek to exploit the ancient language for their own nefarious purposes.\n",
      "\n",
      "#### Stakes\n",
      "The fate of the fragile ecological recovery hangs in the balance; mis \n",
      "\n",
      "=== SCENE JSON ===\n",
      "{\n",
      "  \"location\": \"Earth, 22nd century, secluded university library\",\n",
      "  \"time\": \"Twilight\",\n",
      "  \"weather\": \"Overcast with distant thunder\",\n",
      "  \"mood\": \"Tense yet determined\",\n",
      "  \"pov\": \"Third person limited, following Dr. Elara Morgenstern\",\n",
      "  \"camera_style\": \"Close-ups and wide shots to capture Dr. Morgenstern's focused expression and the vast, quiet library\",\n",
      "  \"characters\": [\n",
      "    {\n",
      "      \"name\": \"Dr. Elara Morgenstern\",\n",
      "      \"role\": \"Protagonist\",\n",
      "      \"objective\": \"Harness the ancient script for healing\",\n",
      "      \"emotion\": \"Curiosity mixed with apprehension\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Kai Lin\",\n",
      "      \"role\": \"Ally\",\n",
      "      \"objective\": \"Protect the manuscript and assist Dr. Morgenstern\",\n",
      "      \"emotion\": \"Determined\"\n",
      "    }\n",
      "  ],\n",
      "  \"key_props\": [\n",
      "    \"ancient manuscript\",\n",
      "    \"cybersecurity\",\n",
      "    \"storm-summoning language\"\n",
      "  ],\n",
      "  \"beats\": [\n",
      "    \"Discovery of the manuscript\",\n",
      "    \"First successful summoning of rain\",\n",
      "    \"Attempted theft by the Weather Wielders\",\n",
      "    \"Formation of an alliance with Kai Lin\",\n",
      "    \"Mastery of the language and prevention of a catastrophe\"\n",
      "  ],\n",
      "  \"sensory\": [\n",
      "    {\n",
      "      \"modality\": \"Visual\",\n",
      "      \"detail\": \"The dim light of the library casting long shadows over the ancient manuscript\"\n",
      "    },\n",
      "    {\n",
      "      \"modality\": \"Auditory\",\n",
      "      \"detail\": \"The distant rumble of thunder, punctuating the tense silence\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== SCENE PROSE ===\n",
      " In the musty twilight of the Earth's future university library, the overcast sky seemed to press down upon the world with the weight of impending storms. Dr. Elara Morgenstern moved through the labyrinthine stacks with the quiet determination of one on a sacred quest. Each step reverberated off the marbled floor, mirroring her racing thoughts—a symphony of curiosity and caution played out within. The ancient manuscript lay before her, its pages whispering secrets long forgotten, while Dr. Morgenstern's fingers traced the symbols of cybersecurity woven into the very fabric of this arcane knowledge.\n",
      "\n",
      "\n",
      "Suddenly, the library's hush was broken by the first drumroll of rain against the high windows, the language of the weather still unmastered. An unexpected force of nature, now meticulously directed through centuries-old text. It wasn't just any storm; it was purposeful, resonating with power that hummed within the air itself.\n",
      "\n",
      "\n",
      "The portrayal switched focus to the sharp gaze of Dr. Morgenstern, the intent in her eyes reflecting the deep responsibility she felt. Beside her stood Kai Lin, the ally who had matched her resolve like few others could. Their joint effort bore the dual goals of protection and enlightenment, an undertaking too significant for the rogue hands of the Weather Wielders who sought control of such ancient forces.\n",
      "\n",
      "\n",
      "As they delved deeper into the language of the storm, every revelation brought them closer to not only understanding but also mastering the elemental dialogue. Together, they would stand guardians against chaos, keeping the tempest's heart safe from those who would misuse its breath. \n",
      "\n",
      "=== DIALOGUE ===\n",
      " SPEAKER: Mira\n",
      "(With determination masking underlying fear) \"The coastal breeze calls to me tonight. Is it worth risking all we’ve learned?\"\n",
      "\n",
      "SPEAKER: Arjun\n",
      "(Exasperated but concerned) \"Mira, you know my stance on this. A miscast spell can carry dire consequences.\"\n",
      "\n",
      "SPEAKER: Mira\n",
      "(Analyzes his expression before replying) \"I understand, yet I believe in refining our control with practice.\"\n",
      "\n",
      "SPEAKER: Arjun\n",
      "(Nods solemnly, then presents a rare artifact) \"Perhaps if you handle this talisman—a token of ancient protection—you might ease my worries.\"\n",
      "\n",
      "SPEAKER: Mira\n",
      "(Eyes sparkling, cautiously optimistic) \"It won't distract from respecting nature's power, will it? Let's proceed, subtly yet purposefully.\" \n",
      "\n",
      "=== STYLE-TRANSFERRED ===\n",
      " In the ethereal glow of the Earth's future university library, where the air hangs heavy with secrets, Dr. Elara Morgenstern wanders amid the towering shelves. Her steps are soft whispers on the polished stones, each echo a testament to her unwavering resolve. She cradles the tome of cybersecurity, an age-old relic whose murmurs speak of wisdom long shrouded in shadow. With every page turned, she deciphers the intricate dance of code and lore, her heart beating in time with the silent rhythm of discovery.\n",
      "\n",
      "\n",
      "Outside, the heavens weep, and the skies conspire to sing a song of power. This tempest, a breath drawn from the tome, swirls with intent, its voice a chorus of thunderous ambition. It speaks in tongues only the worthy can comprehend, a symphony orchestrated by the sages of yore.\n",
      "\n",
      "\n",
      "At Dr. Morgenstern's side, Kai Lin stands resolute, their partnership as steadfast as the ancient walls that surround them. Together, they embark on a journey to commune with the storm's soul, to harness its fierce beauty and safeguard it from the covetous gaze of the Weather Wielders. These rogues, cloaked in the guise of custodians, hunger for dominion over the elements. Yet, Dr. Morgenstern and Kai Lin, armored in knowledge and camaraderie, are poised to become the sentinels of harmony, ensuring that the tempest's essence remains a gift to all, not a weapon in the hands of the few.\n",
      "\n",
      "\n",
      "Their quest is a tapestry of light and shadow, a tale woven from the threads of a world where magic and technology intertwine. As they navigate the labyrinth of the past and present, they embrace the challenge laid before them, a pledge to protect the equilibrium of a world teetering on the brink of wonder and upheaval.\n",
      "\n",
      "\n",
      "------------------------- How would you describe the atmosphere of the Earth's future university library using more vivid, sensory details to enhance the magical realism?\n",
      "\n",
      "\n",
      "**Elaborated textbook-level solution:**\n",
      "\n",
      "The atmosphere of the Earth's future university library is a confluence of the tangible and the mystical. Upon entering, one is immediately enveloped in a cocoon of hushed anticipation, the scent of aged parchment mingling with the subtle hint of ozone, as if the very air is charged with the electricity of latent knowledge. The walls, lined with towering bookshelves, seem to pulse with the soft, rhythmic heartbeat of countless stories, each beat a whisper of the lives and secrets contained within.\n",
      "\n",
      "\n",
      "In the dim, diffused light filtering through stained glass windows, the colors cast a kaleidoscope of patterns across the library's expanse, painting the scene with the surreal hues of dreamscape. The air thrums with a quiet intensity\n"
     ]
    }
   ],
   "source": [
    "seed = \"A shy linguistics student discovers a dead language can summon storms.\"\n",
    "expanded = expand_prompt(seed)\n",
    "print(\"=== EXPANDED PROMPT ===\\n\", expanded[:1200], \"\\n\")\n",
    "\n",
    "scene_plan = scene_json_from_outline(expanded, beat_index=1)\n",
    "print(\"=== SCENE JSON ===\")\n",
    "print(json.dumps(scene_plan.model_dump(), ensure_ascii=False, indent=2))\n",
    "\n",
    "scene_text = render_scene_prose(scene_plan, target_len=180)\n",
    "print(\"\\n=== SCENE PROSE ===\\n\", scene_text, \"\\n\")\n",
    "\n",
    "chars = [\n",
    "    {\"name\":\"Mira\",\"role\":\"protagonist\",\"objective\":\"test the storm-chant safely\",\"emotion\":\"guarded\"},\n",
    "    {\"name\":\"Arjun\",\"role\":\"mentor\",\"objective\":\"discourage reckless use\",\"emotion\":\"anxious\"}\n",
    "]\n",
    "dialogue = generate_dialogue(chars,\n",
    "                             scene_goal=\"Negotiate boundaries for trying the chant on the pier.\",\n",
    "                             conflict_axis=\"curiosity vs caution\",\n",
    "                             turns=8)\n",
    "print(\"=== DIALOGUE ===\\n\", dialogue, \"\\n\")\n",
    "\n",
    "styled = style_transfer(scene_text, \"magical realism with lightly lyrical cadence, restrained metaphors, present tense\")\n",
    "print(\"=== STYLE-TRANSFERRED ===\\n\", styled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691edb5-9451-4ead-a64f-4aeadff416d3",
   "metadata": {},
   "source": [
    "## Notes, tips, and swaps\n",
    "\n",
    "### Model swaps:\n",
    "\n",
    "Small & easy: microsoft/Phi-3-mini-4k-instruct, Qwen/Qwen2.5-3B-Instruct.\n",
    "\n",
    "Mid/heavier: meta-llama/Meta-Llama-3.1-8B-Instruct.\n",
    "\n",
    "If you prefer GGUF models via llama-cpp-python, load with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456c13b-cc8e-4c81-bf54-90d1853dd4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
