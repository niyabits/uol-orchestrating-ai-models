{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f45232-6b03-4b96-8455-62b428686174",
   "metadata": {},
   "source": [
    "# Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810754dd-ac40-4e78-b48f-a656bcf2c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers torch accelerate sentencepiece pydantic==2.\\* orjson --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b530a66-35fc-4a45-adf0-68f6f8a40bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, math, textwrap, orjson, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a36f48-5c0a-4699-8786-41be7aa15f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2cee70c3ec49f7865ca380c447cebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10bc100d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE  = torch.bfloat16 if DEVICE==\"cuda\" and torch.cuda.is_bf16_supported() else torch.float16\n",
    "\n",
    "# Choose a small, open, instruction-tuned model that runs on CPU/GPU:\n",
    "# Good starters: \"microsoft/Phi-3-mini-4k-instruct\" (2.7B), \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# Heavier (needs good GPU/RAM): \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    dtype=DTYPE,\n",
    "    device_map=\"auto\" if DEVICE==\"cuda\" else None\n",
    ").to(DEVICE)\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_special_tokens=True)\n",
    "SEED = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a648e-b5b0-4a24-ab70-d9bd055d990c",
   "metadata": {},
   "source": [
    "## A disciplined generate() helper\n",
    "\n",
    "- Why: Stable decoding & repeatable experiments.\n",
    "- Adds anti-repetition and length controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b132d874-8b69-4e79-8f0c-c7b7e37ba482",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecodeCfg:\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.8\n",
    "    top_p: float = 0.9\n",
    "    top_k: int = 0\n",
    "    repetition_penalty: float = 1.05\n",
    "    stop: Optional[List[str]] = None\n",
    "\n",
    "def generate(prompt: str, cfg: DecodeCfg = DecodeCfg()) -> str:\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            **input_ids,\n",
    "            max_new_tokens=cfg.max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=cfg.temperature,\n",
    "            top_p=cfg.top_p,\n",
    "            top_k=cfg.top_k,\n",
    "            repetition_penalty=cfg.repetition_penalty,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    text = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "    # Strip the leading prompt (works for many instruct models)\n",
    "    return text[len(prompt):].strip() if text.startswith(prompt) else text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea55e95-7990-49d1-9e52-002545c5692b",
   "metadata": {},
   "source": [
    "## Prompt Expansion\n",
    "\n",
    "Goal: Take a terse logline and produce a rich, multi-angle expansion (themes, conflicts, beats, constraints). Few-shot prompt sets expectations and yields structured bullets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fd5bdb-b81e-4b13-b7e6-d864fb23a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPANSION_SYSTEM = \"\"\"You are a narrative development assistant.\n",
    "Expand terse story prompts into a structured creative brief with:\n",
    "- Premise (1–2 sentences)\n",
    "- World/Setting (specific time/place, social context)\n",
    "- Themes (3 bullets)\n",
    "- Protagonist & Goal (bio + objective)\n",
    "- Antagonistic Force (person/system/internal)\n",
    "- Stakes (why it matters)\n",
    "- Constraints (tone, POV, target length)\n",
    "- 5-Beat Outline (Beat #: heading + 1–2 lines)\n",
    "Return clean Markdown with headings and bullets.\n",
    "\"\"\"\n",
    "\n",
    "def expand_prompt(seed_prompt: str) -> str:\n",
    "    user = f\"Seed prompt: {seed_prompt}\\n\\nProduce the structured expansion now.\"\n",
    "    prompt = f\"<|system|>\\n{EXPANSION_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=700, temperature=0.8, top_p=0.9))\n",
    "\n",
    "# Example:\n",
    "expanded = expand_prompt(\"A shy linguistics student discovers a dead language can summon storms.\")\n",
    "# print(expanded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6d5f0-5057-4a07-b310-5bb394fbb6eb",
   "metadata": {},
   "source": [
    "## 3) Scene Description (schema → prose, with JSON validation)\n",
    "\n",
    "Goal: Derive a scene graph (who/where/when/mood/visuals/sensory beats) then synthesize evocative prose. We first ask for strict JSON (schema below), then render prose from it. If the model returns invalid JSON, we repair it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ee4db9-3705-48d9-b05c-18704357dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====RAW=======\n",
      "You output ONLY valid JSON matching this Pydantic schema:\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"Character\": {\n",
      "      \"properties\": {\n",
      "        \"name\": {\n",
      "          \"title\": \"Name\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"role\": {\n",
      "          \"title\": \"Role\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"objective\": {\n",
      "          \"title\": \"Objective\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"emotion\": {\n",
      "          \"title\": \"Emotion\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"name\",\n",
      "        \"role\",\n",
      "        \"objective\",\n",
      "        \"emotion\"\n",
      "      ],\n",
      "      \"title\": \"Character\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"SensoryBeat\": {\n",
      "      \"properties\": {\n",
      "        \"modality\": {\n",
      "          \"title\": \"Modality\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"detail\": {\n",
      "          \"title\": \"Detail\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"modality\",\n",
      "        \"detail\"\n",
      "      ],\n",
      "      \"title\": \"SensoryBeat\",\n",
      "      \"type\": \"object\"\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"location\": {\n",
      "      \"title\": \"Location\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"time\": {\n",
      "      \"title\": \"Time\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"weather\": {\n",
      "      \"title\": \"Weather\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"mood\": {\n",
      "      \"title\": \"Mood\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"pov\": {\n",
      "      \"title\": \"Pov\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"camera_style\": {\n",
      "      \"title\": \"Camera Style\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"characters\": {\n",
      "      \"items\": {\n",
      "        \"$ref\": \"#/$defs/Character\"\n",
      "      },\n",
      "      \"title\": \"Characters\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"key_props\": {\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Key Props\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"beats\": {\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Beats\",\n",
      "      \"type\": \"array\"\n",
      "    },\n",
      "    \"sensory\": {\n",
      "      \"items\": {\n",
      "        \"$ref\": \"#/$defs/SensoryBeat\"\n",
      "      },\n",
      "      \"title\": \"Sensory\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"location\",\n",
      "    \"time\",\n",
      "    \"weather\",\n",
      "    \"mood\",\n",
      "    \"pov\",\n",
      "    \"camera_style\",\n",
      "    \"characters\",\n",
      "    \"beats\",\n",
      "    \"sensory\"\n",
      "  ],\n",
      "  \"title\": \"SceneSchema\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "No comments, no Markdown, no backticks—just JSON.\n",
      "\n",
      " Given this expanded outline (Markdown), select Beat #1 and produce a scene JSON instance.\n",
      "\n",
      "Expanded Outline:\n",
      "You are a narrative development assistant.\n",
      "Expand terse story prompts into a structured creative brief with:\n",
      "- Premise (1–2 sentences)\n",
      "- World/Setting (specific time/place, social context)\n",
      "- Themes (3 bullets)\n",
      "- Protagonist & Goal (bio + objective)\n",
      "- Antagonistic Force (person/system/internal)\n",
      "- Stakes (why it matters)\n",
      "- Constraints (tone, POV, target length)\n",
      "- 5-Beat Outline (Beat #: heading + 1–2 lines)\n",
      "Return clean Markdown with headings and bullets.\n",
      "\n",
      " Seed prompt: A shy linguistics student discovers a dead language can summon storms.\n",
      "\n",
      "Produce the structured expansion now.\n",
      " # Creative Brief: \"Whispers of the Storm\"\n",
      "\n",
      "## Premise\n",
      "A reserved college student uncovers an ancient text that reveals a forgotten dialect's power to control weather patterns.\n",
      "\n",
      "## World/Setting\n",
      "- **Time Period**: Late 19th century\n",
      "- **Place**: Oxford University, England\n",
      "- **Social Context**: Victorian era - Science is making rapid advancements but superstitions about the arcane persist.\n",
      "\n",
      "## Themes\n",
      "- The intertwining of nature and knowledge\n",
      "- The conflict between science and mythology\n",
      "- Self-discovery through hidden history\n",
      "\n",
      "## Protagonist & Goal\n",
      "- **Protagonist Name**: Evelyn Arden\n",
      "- **Background**: Linguistics PhD Candidate at Oxford University; introverted, intellectually curious, has always felt out of place in academia.\n",
      "- **Objective**: To decipher the mysterious ancient manuscript without unleashing its potentially destructive powers upon the world.\n",
      "\n",
      "## Antagonistic Force\n",
      "- An insidious cabal of scholars who believe the protagonist holds the key to their dominance over natural elements.\n",
      "\n",
      "## Stakes\n",
      "The discovery could either revolutionize humanity’s understanding of language and nature or cause catastrophic climate events if misused.\n",
      "\n",
      "## Constraints\n",
      "- **Tone**: Mysterious yet scholarly\n",
      "- **Point of View**: Third person limited, closely following Evelyn's perspective\n",
      "- **Target Length**: Approximately 8000 words for a novella\n",
      "\n",
      "## 5-Beat Outline\n",
      "\n",
      "### Beat 1: Revelation\n",
      "Evelyn stumbles upon a leather-bound tome buried within the university archives, its pages filled with symbols from an extinct civilization. Her fingers trace the glyphs as thunder rumbles outside—a prelude to her impending journey.\n",
      "\n",
      "### Beat 2: Experimentation\n",
      "Under the cloak of night, she experiments with spoken incantations, unwittingly conjuring a gentle breeze before witnessing lightning strike nearby buildings—her academic peers grow suspicious.\n",
      "\n",
      "### Beat 3: Interference\n",
      "Rival scholars become increasingly hostile, seeking the book for themselves. Evelyn must protect her find while grappling with her newfound ability, which tempts her with promises of fame and recognition.\n",
      "\n",
      "### Beat 4: Escalation\n",
      "As tempests rise in intensity with every chant, so does the pressure on Evelyn. She narrowly avoids disaster when one such experiment goes awry, leading her to realize the gravity of her actions.\n",
      "\n",
      "### Beat 5: Resolution\n",
      "With guidance from an elderly professor and careful study, Evelyn masters her abilities, using them responsibly to bring relief during drought conditions, thus earning respect and safeguarding both herself and humankind from greater harm.\n",
      "\n",
      " ```json\n",
      "{\n",
      "  \"location\": \"Oxford University, England\",\n",
      "  \"time\": \"Late 19th century\",\n",
      "  \"weather\": \"Overcast with distant thunder\",\n",
      "  \"mood\": \"Tense and anticipatory\",\n",
      "  \"pov\": \"Third person limited, following Evelyn's perspective\",\n",
      "  \"camera_style\": \"Close-up shots of Evelyn's hands as she deciphers the manuscript, wide shots of the university's Gothic architecture\",\n",
      "  \"characters\": [\n",
      "    {\n",
      "      \"name\": \"Evelyn Arden\",\n",
      "      \"role\": \"Protagonist\",\n",
      "      \"objective\": \"To decipher the ancient manuscript without unleashing its powers\"\n",
      "    }\n",
      "  ],\n",
      "  \"key_props\": [\n",
      "    \"ancient manuscript\",\n",
      "    \"linguistics PhD\",\n",
      "    \"extinct civilization\",\n",
      "    \"natural elements\",\n",
      "    \"academic rivalry\"\n",
      "  ],\n",
      "  \"beats\": [\n",
      "    \"Evelyn discovers the ancient manuscript in the university archives.\",\n",
      "    \"She experiments with the incantations and accidentally summons a breeze.\",\n",
      "    \"Her peers grow suspicious of her activities.\",\n",
      "    \"Rival scholars seek the book, increasing the danger.\",\n",
      "    \"Evelyn learns to control her abilities responsibly.\"\n",
      "  ],\n",
      "  \"sensory\": [\n",
      "    {\n",
      "      \"modality\": \"Visual\",\n",
      "      \"detail\": \"Close-up shots of Evelyn's hands as she deciphers the manuscript.\"\n",
      "    },\n",
      "    {\n",
      "      \"modality\": \"Auditory\",\n",
      "      \"detail\": \"The distant rumble of thunder and the occasional crack of lightning.\"\n",
      "    },\n",
      "    {\n",
      "      \"modality\": \"Tactile\",\n",
      "      \"detail\": \"The feel of the ancient, leather-bound tome in Evelyn's hands.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "unexpected content after document: line 118 column 1 (char 2102)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 46\u001b[0m, in \u001b[0;36mscene_json_from_outline\u001b[0;34m(expanded_outline_md, beat_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43morjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SceneSchema\u001b[38;5;241m.\u001b[39mmodel_validate(data)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: unexpected character: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generate(prompt, DecodeCfg(max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.85\u001b[39m, top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, repetition_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.03\u001b[39m))\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mscene_json_from_outline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeat_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(sc)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(render_scene_prose(sc))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 54\u001b[0m, in \u001b[0;36mscene_json_from_outline\u001b[0;34m(expanded_outline_md, beat_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not return JSON.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext[:\u001b[38;5;241m800\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43morjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SceneSchema\u001b[38;5;241m.\u001b[39mmodel_validate(data)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: unexpected content after document: line 118 column 1 (char 2102)"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "    objective: str\n",
    "    emotion: str\n",
    "\n",
    "class SensoryBeat(BaseModel):\n",
    "    modality: str  # e.g., \"visual\", \"auditory\", \"tactile\", \"olfactory\"\n",
    "    detail: str\n",
    "\n",
    "class SceneSchema(BaseModel):\n",
    "    location: str\n",
    "    time: str\n",
    "    weather: str\n",
    "    mood: str\n",
    "    pov: str\n",
    "    camera_style: str\n",
    "    characters: List[Character]\n",
    "    key_props: List[str] = Field(default_factory=list)\n",
    "    beats: List[str]\n",
    "    sensory: List[SensoryBeat]\n",
    "\n",
    "SCHEMA_JSON = json.dumps(SceneSchema.model_json_schema(), indent=2)\n",
    "\n",
    "SCHEMA_SYSTEM = f\"\"\"You output ONLY valid JSON matching this Pydantic schema:\n",
    "{SCHEMA_JSON}\n",
    "No comments, no Markdown, no backticks—just JSON.\n",
    "\"\"\"\n",
    "\n",
    "def scene_json_from_outline(expanded_outline_md: str, beat_index: int = 1) -> SceneSchema:\n",
    "    user = f\"\"\"Given this expanded outline (Markdown), select Beat #{beat_index} and produce a scene JSON instance.\n",
    "\n",
    "Expanded Outline:\n",
    "{expanded_outline_md}\n",
    "\"\"\"\n",
    "    prompt = f\"<|system|>\\n{SCHEMA_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    raw = generate(prompt, DecodeCfg(max_new_tokens=600, temperature=0.4, top_p=0.95, repetition_penalty=1.01))\n",
    "    # Attempt JSON parsing with a light repair (strip code fences, stray text)\n",
    "    text = raw.strip()\n",
    "    print(\"=====RAW=======\")\n",
    "    print(text)\n",
    "    text = re.sub(r\"^```(?:json)?|```$\", \"\", text, flags=re.IGNORECASE|re.MULTILINE).strip()\n",
    "    try:\n",
    "        data = orjson.loads(text)\n",
    "        return SceneSchema.model_validate(data)\n",
    "    except Exception as e:\n",
    "        # Minimal heuristic fix: find the first {...} block\n",
    "        m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "        if not m:\n",
    "            raise RuntimeError(f\"Model did not return JSON.\\n---\\n{text[:800]}\")\n",
    "        try:\n",
    "            data = orjson.loads(m.group(0))\n",
    "            return SceneSchema.model_validate(data)\n",
    "        except ValidationError as ve:\n",
    "            raise ve\n",
    "\n",
    "def render_scene_prose(scene: SceneSchema, target_len: int = 180) -> str:\n",
    "    guide = f\"\"\"Write ~{target_len} words of vivid third-person limited prose.\n",
    "Keep internal state consistent with 'pov'. Use camera_style as inspiration for sentence rhythm and framing.\n",
    "Weave in at least 2 sensory beats. Avoid cliché.\n",
    "\"\"\"\n",
    "    content_plan = json.dumps(scene.model_dump(), ensure_ascii=False, indent=2)\n",
    "    prompt = f\"<|system|>\\nYou turn structured scene plans into concise, evocative prose.\\n<|user|>\\nScene Plan (JSON):\\n{content_plan}\\n\\nInstructions:\\n{guide}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=400, temperature=0.85, top_p=0.9, repetition_penalty=1.03))\n",
    "\n",
    "# Example:\n",
    "sc = scene_json_from_outline(expanded, beat_index=1)\n",
    "print(sc)\n",
    "# print(render_scene_prose(sc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d166f16-b29c-4c26-bdfd-de4ee39bf51f",
   "metadata": {},
   "source": [
    "## 4) Character Dialogue (role conditioning + turn budget + beats)\n",
    "\n",
    "We build speaker profiles and constrain output to a screenplay-like format with a turn budget and inline subtext cues in stage directions (kept short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64013dc8-4cb1-4e06-8093-e9905edc7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALOGUE_SYSTEM = \"\"\"You write snappy, character-driven dialogue.\n",
    "Output format:\n",
    "SPEAKER: line\n",
    "  (stage direction / subtext)\n",
    "No narration; only dialogue and concise stage directions.\n",
    "Honor each character's objective and emotion. Keep lines short (≤18 words).\n",
    "\"\"\"\n",
    "\n",
    "def generate_dialogue(characters: List[Dict[str, str]],\n",
    "                      scene_goal: str,\n",
    "                      conflict_axis: str,\n",
    "                      turns: int = 10) -> str:\n",
    "    roster = \"\\n\".join(f\"- {c['name']} ({c['role']}), objective: {c['objective']}, emotion: {c['emotion']}\" for c in characters)\n",
    "    user = f\"\"\"Characters:\n",
    "{roster}\n",
    "\n",
    "Scene goal: {scene_goal}\n",
    "Primary conflict axis: {conflict_axis}\n",
    "Turn budget: {turns}\n",
    "\n",
    "Write dialogue now.\"\"\"\n",
    "    prompt = f\"<|system|>\\n{DIALOGUE_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=500, temperature=0.9, top_p=0.92, repetition_penalty=1.06))\n",
    "\n",
    "# Example:\n",
    "# chars = [\n",
    "#     {\"name\":\"Mira\",\"role\":\"protagonist\",\"objective\":\"convince Arjun to leave\",\"emotion\":\"wary\"},\n",
    "#     {\"name\":\"Arjun\",\"role\":\"foil\",\"objective\":\"stall for time\",\"emotion\":\"deflective\"},\n",
    "# ]\n",
    "# dlg = generate_dialogue(chars, \"Mira tries to get Arjun out before the storm hits.\", \"trust vs control\", turns=8)\n",
    "# print(dlg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a92d5d-7efd-4f9b-adf7-46bc973aacdf",
   "metadata": {},
   "source": [
    "## 5) Style Transfer (tone) with a two-pass content-preservation plan\n",
    "\n",
    "Single-shot “rewrite in style X” often drifts. We mitigate with content planning:\n",
    "\n",
    "Extract a content plan (facts, plot beats, entities) in JSON.\n",
    "\n",
    "Rewrite to a target style/tone while anchoring to the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ddb55eb-f04b-41b4-906b-8330c04a70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_PLAN_SYSTEM = \"\"\"Extract a content plan JSON with keys:\n",
    "- entities: [{name, type, attributes?}]\n",
    "- events: [{order, summary}]\n",
    "- constraints: [{kind, text}]  # e.g., must-keep metaphors, lexical items\n",
    "Output only JSON (no markdown).\n",
    "\"\"\"\n",
    "\n",
    "def extract_content_plan(text: str) -> Dict[str, Any]:\n",
    "    user = f\"Extract the content plan from this passage:\\n{text}\\n\"\n",
    "    prompt = f\"<|system|>\\n{CONTENT_PLAN_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    raw = generate(prompt, DecodeCfg(max_new_tokens=500, temperature=0.3, top_p=0.9, repetition_penalty=1.01))\n",
    "    raw = re.sub(r\"^```(?:json)?|```$\", \"\", raw, flags=re.IGNORECASE|re.MULTILINE).strip()\n",
    "    plan = json.loads(re.search(r\"\\{.*\\}\", raw, flags=re.DOTALL).group(0))\n",
    "    return plan\n",
    "\n",
    "STYLE_TRANSFER_SYSTEM = \"\"\"You perform style transfer while preserving content.\n",
    "Rules:\n",
    "- Faithfully preserve entities and event order from the plan.\n",
    "- Apply the requested tone/style features.\n",
    "- Avoid archaic words unless asked.\n",
    "- Keep output length within ±15% of the input length unless asked.\n",
    "\"\"\"\n",
    "\n",
    "def style_transfer(text: str, target_style: str) -> str:\n",
    "    plan = extract_content_plan(text)\n",
    "    plan_json = json.dumps(plan, ensure_ascii=False, indent=2)\n",
    "    user = f\"\"\"Target style/tone: {target_style}\n",
    "\n",
    "Content plan (must preserve):\n",
    "{plan_json}\n",
    "\n",
    "Source passage:\n",
    "{text}\n",
    "\n",
    "Rewrite now in the target style while preserving facts and ordering.\"\"\"\n",
    "    prompt = f\"<|system|>\\n{STYLE_TRANSFER_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=700, temperature=0.7, top_p=0.9, repetition_penalty=1.02))\n",
    "\n",
    "# Example:\n",
    "# src = \"Mira stepped onto the flooded platform, the loudspeakers coughing warnings as wind bent the halyard.\"\n",
    "# print(style_transfer(src, \"noir, clipped sentences, wry subtext, contemporary diction\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943ae8d-6ee4-44e9-88e4-acd6ff04372f",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774aa0ba-c621-4da4-a449-1e7a17e027dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPANDED PROMPT ===\n",
      " You are a narrative development assistant.\n",
      "Expand terse story prompts into a structured creative brief with:\n",
      "- Premise (1–2 sentences)\n",
      "- World/Setting (specific time/place, social context)\n",
      "- Themes (3 bullets)\n",
      "- Protagonist & Goal (bio + objective)\n",
      "- Antagonistic Force (person/system/internal)\n",
      "- Stakes (why it matters)\n",
      "- Constraints (tone, POV, target length)\n",
      "- 5-Beat Outline (Beat #: heading + 1–2 lines)\n",
      "Return clean Markdown with headings and bullets.\n",
      "\n",
      " Seed prompt: A shy linguistics student discovers a dead language can summon storms.\n",
      "\n",
      "Produce the structured expansion now.\n",
      " # Creative Brief: \"Whispers of the Storm\"\n",
      "\n",
      "## Premise\n",
      "A reserved college student uncovers an ancient text that reveals a forgotten dialect's power to control weather patterns.\n",
      "\n",
      "## World/Setting\n",
      "- **Time Period**: Late 19th century\n",
      "- **Place**: Oxford University, England\n",
      "- **Social Context**: Victorian era - Science is making rapid advancements but superstitions about the arcane persist.\n",
      "\n",
      "## Themes\n",
      "- The intertwining of nature and knowledge\n",
      "- The conflict between science and mythology\n",
      "- Self-discovery through hidden history\n",
      "\n",
      "## Protagonist & Goal\n",
      "- **Protagonist Name**: Evelyn Arden\n",
      "- **Background**: Linguisti \n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "unexpected content after document: line 118 column 1 (char 2102)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m, in \u001b[0;36mscene_json_from_outline\u001b[0;34m(expanded_outline_md, beat_index)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43morjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SceneSchema\u001b[38;5;241m.\u001b[39mmodel_validate(data)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: unexpected character: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m expanded \u001b[38;5;241m=\u001b[39m expand_prompt(seed)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== EXPANDED PROMPT ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, expanded[:\u001b[38;5;241m1200\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m scene_plan \u001b[38;5;241m=\u001b[39m \u001b[43mscene_json_from_outline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeat_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== SCENE JSON ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(scene_plan\u001b[38;5;241m.\u001b[39mmodel_dump(), ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[9], line 52\u001b[0m, in \u001b[0;36mscene_json_from_outline\u001b[0;34m(expanded_outline_md, beat_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not return JSON.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext[:\u001b[38;5;241m800\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43morjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SceneSchema\u001b[38;5;241m.\u001b[39mmodel_validate(data)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: unexpected content after document: line 118 column 1 (char 2102)"
     ]
    }
   ],
   "source": [
    "seed = \"A shy linguistics student discovers a dead language can summon storms.\"\n",
    "expanded = expand_prompt(seed)\n",
    "print(\"=== EXPANDED PROMPT ===\\n\", expanded[:1200], \"\\n\")\n",
    "\n",
    "scene_plan = scene_json_from_outline(expanded, beat_index=1)\n",
    "print(\"=== SCENE JSON ===\")\n",
    "print(json.dumps(scene_plan.model_dump(), ensure_ascii=False, indent=2))\n",
    "\n",
    "scene_text = render_scene_prose(scene_plan, target_len=180)\n",
    "print(\"\\n=== SCENE PROSE ===\\n\", scene_text, \"\\n\")\n",
    "\n",
    "chars = [\n",
    "    {\"name\":\"Mira\",\"role\":\"protagonist\",\"objective\":\"test the storm-chant safely\",\"emotion\":\"guarded\"},\n",
    "    {\"name\":\"Arjun\",\"role\":\"mentor\",\"objective\":\"discourage reckless use\",\"emotion\":\"anxious\"}\n",
    "]\n",
    "dialogue = generate_dialogue(chars,\n",
    "                             scene_goal=\"Negotiate boundaries for trying the chant on the pier.\",\n",
    "                             conflict_axis=\"curiosity vs caution\",\n",
    "                             turns=8)\n",
    "print(\"=== DIALOGUE ===\\n\", dialogue, \"\\n\")\n",
    "\n",
    "styled = style_transfer(scene_text, \"magical realism with lightly lyrical cadence, restrained metaphors, present tense\")\n",
    "print(\"=== STYLE-TRANSFERRED ===\\n\", styled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691edb5-9451-4ead-a64f-4aeadff416d3",
   "metadata": {},
   "source": [
    "## Notes, tips, and swaps\n",
    "\n",
    "### Model swaps:\n",
    "\n",
    "Small & easy: microsoft/Phi-3-mini-4k-instruct, Qwen/Qwen2.5-3B-Instruct.\n",
    "\n",
    "Mid/heavier: meta-llama/Meta-Llama-3.1-8B-Instruct.\n",
    "\n",
    "If you prefer GGUF models via llama-cpp-python, load with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456c13b-cc8e-4c81-bf54-90d1853dd4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
