{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f45232-6b03-4b96-8455-62b428686174",
   "metadata": {},
   "source": [
    "# Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810754dd-ac40-4e78-b48f-a656bcf2c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U transformers torch accelerate sentencepiece pydantic==2.\\* orjson --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b530a66-35fc-4a45-adf0-68f6f8a40bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, math, textwrap, orjson, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a36f48-5c0a-4699-8786-41be7aa15f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4312eff39840a5ba3066789af4b46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8cfefa8107470dab20282430475634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91aa9af1d6a44239ab039cbe776f7591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefce0305b954fd4aa9712951544cd38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7498d011d58545b9b42ec61fe7a3066f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1128080d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE  = torch.bfloat16 if DEVICE==\"cuda\" and torch.cuda.is_bf16_supported() else torch.float16\n",
    "\n",
    "# Choose a small, open, instruction-tuned model that runs on CPU/GPU:\n",
    "# Good starters: \"microsoft/Phi-3-mini-4k-instruct\" (2.7B), \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# Heavier (needs good GPU/RAM): \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    dtype=DTYPE,\n",
    "    device_map=\"auto\" if DEVICE==\"cuda\" else None\n",
    ").to(DEVICE)\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_special_tokens=True)\n",
    "SEED = 42\n",
    "random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a648e-b5b0-4a24-ab70-d9bd055d990c",
   "metadata": {},
   "source": [
    "## A disciplined generate() helper\n",
    "\n",
    "- Why: Stable decoding & repeatable experiments.\n",
    "- Adds anti-repetition and length controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b132d874-8b69-4e79-8f0c-c7b7e37ba482",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecodeCfg:\n",
    "    max_new_tokens: int = 512\n",
    "    temperature: float = 0.8\n",
    "    top_p: float = 0.9\n",
    "    top_k: int = 0\n",
    "    repetition_penalty: float = 1.05\n",
    "    stop: Optional[List[str]] = None\n",
    "\n",
    "def generate(prompt: str, cfg: DecodeCfg = DecodeCfg()) -> str:\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            **input_ids,\n",
    "            max_new_tokens=cfg.max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=cfg.temperature,\n",
    "            top_p=cfg.top_p,\n",
    "            top_k=cfg.top_k,\n",
    "            repetition_penalty=cfg.repetition_penalty,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    text = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "    # Strip the leading prompt (works for many instruct models)\n",
    "    return text[len(prompt):].strip() if text.startswith(prompt) else text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea55e95-7990-49d1-9e52-002545c5692b",
   "metadata": {},
   "source": [
    "## Prompt Expansion\n",
    "\n",
    "Goal: Take a terse logline and produce a rich, multi-angle expansion (themes, conflicts, beats, constraints). Few-shot prompt sets expectations and yields structured bullets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37fd5bdb-b81e-4b13-b7e6-d864fb23a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPANSION_SYSTEM = \"\"\"You are a narrative development assistant.\n",
    "Expand terse story prompts into a structured creative brief with:\n",
    "- Premise (1–2 sentences)\n",
    "- World/Setting (specific time/place, social context)\n",
    "- Themes (3 bullets)\n",
    "- Protagonist & Goal (bio + objective)\n",
    "- Antagonistic Force (person/system/internal)\n",
    "- Stakes (why it matters)\n",
    "- Constraints (tone, POV, target length)\n",
    "- 5-Beat Outline (Beat #: heading + 1–2 lines)\n",
    "Return clean Markdown with headings and bullets.\n",
    "\"\"\"\n",
    "\n",
    "def expand_prompt(seed_prompt: str) -> str:\n",
    "    user = f\"Seed prompt: {seed_prompt}\\n\\nProduce the structured expansion now.\"\n",
    "    prompt = f\"<|system|>\\n{EXPANSION_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=700, temperature=0.8, top_p=0.9))\n",
    "\n",
    "# Example:\n",
    "expanded = expand_prompt(\"A shy linguistics student discovers a dead language can summon storms.\")\n",
    "# print(expanded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6d5f0-5057-4a07-b310-5bb394fbb6eb",
   "metadata": {},
   "source": [
    "## 3) Scene Description (schema → prose, with JSON validation)\n",
    "\n",
    "Goal: Derive a scene graph (who/where/when/mood/visuals/sensory beats) then synthesize evocative prose. We first ask for strict JSON (schema below), then render prose from it. If the model returns invalid JSON, we repair it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee4db9-3705-48d9-b05c-18704357dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_5/nyy10z0d0nzglbrzhfqsx3tw0000gn/T/ipykernel_64941/612622823.py:25: PydanticDeprecatedSince20: The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  SCHEMA_JSON = SceneSchema.schema_json(indent=2)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "    objective: str\n",
    "    emotion: str\n",
    "\n",
    "class SensoryBeat(BaseModel):\n",
    "    modality: str  # e.g., \"visual\", \"auditory\", \"tactile\", \"olfactory\"\n",
    "    detail: str\n",
    "\n",
    "class SceneSchema(BaseModel):\n",
    "    location: str\n",
    "    time: str\n",
    "    weather: str\n",
    "    mood: str\n",
    "    pov: str\n",
    "    camera_style: str\n",
    "    characters: List[Character]\n",
    "    key_props: List[str] = Field(default_factory=list)\n",
    "    beats: List[str]\n",
    "    sensory: List[SensoryBeat]\n",
    "\n",
    "SCHEMA_JSON = json.dumps(SceneSchema.model_json_schema(), indent=2)\n",
    "\n",
    "SCHEMA_SYSTEM = f\"\"\"You output ONLY valid JSON matching this Pydantic schema:\n",
    "{SCHEMA_JSON}\n",
    "No comments, no Markdown, no backticks—just JSON.\n",
    "\"\"\"\n",
    "\n",
    "def scene_json_from_outline(expanded_outline_md: str, beat_index: int = 1) -> SceneSchema:\n",
    "    user = f\"\"\"Given this expanded outline (Markdown), select Beat #{beat_index} and produce a scene JSON instance.\n",
    "\n",
    "Expanded Outline:\n",
    "{expanded_outline_md}\n",
    "\"\"\"\n",
    "    prompt = f\"<|system|>\\n{SCHEMA_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    raw = generate(prompt, DecodeCfg(max_new_tokens=600, temperature=0.4, top_p=0.95, repetition_penalty=1.01))\n",
    "    # Attempt JSON parsing with a light repair (strip code fences, stray text)\n",
    "    text = raw.strip()\n",
    "    text = re.sub(r\"^```(?:json)?|```$\", \"\", text, flags=re.IGNORECASE|re.MULTILINE).strip()\n",
    "    try:\n",
    "        data = orjson.loads(text)\n",
    "        return SceneSchema.model_validate(data)\n",
    "    except Exception as e:\n",
    "        # Minimal heuristic fix: find the first {...} block\n",
    "        m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "        if not m:\n",
    "            raise RuntimeError(f\"Model did not return JSON.\\n---\\n{text[:800]}\")\n",
    "        try:\n",
    "            data = orjson.loads(m.group(0))\n",
    "            return SceneSchema.model_validate(data)\n",
    "        except ValidationError as ve:\n",
    "            raise ve\n",
    "\n",
    "def render_scene_prose(scene: SceneSchema, target_len: int = 180) -> str:\n",
    "    guide = f\"\"\"Write ~{target_len} words of vivid third-person limited prose.\n",
    "Keep internal state consistent with 'pov'. Use camera_style as inspiration for sentence rhythm and framing.\n",
    "Weave in at least 2 sensory beats. Avoid cliché.\n",
    "\"\"\"\n",
    "    content_plan = json.dumps(scene.model_dump(), ensure_ascii=False, indent=2)\n",
    "    prompt = f\"<|system|>\\nYou turn structured scene plans into concise, evocative prose.\\n<|user|>\\nScene Plan (JSON):\\n{content_plan}\\n\\nInstructions:\\n{guide}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=400, temperature=0.85, top_p=0.9, repetition_penalty=1.03))\n",
    "\n",
    "# Example:\n",
    "sc = scene_json_from_outline(expanded, beat_index=1)\n",
    "print(sc)\n",
    "# print(render_scene_prose(sc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d166f16-b29c-4c26-bdfd-de4ee39bf51f",
   "metadata": {},
   "source": [
    "## 4) Character Dialogue (role conditioning + turn budget + beats)\n",
    "\n",
    "We build speaker profiles and constrain output to a screenplay-like format with a turn budget and inline subtext cues in stage directions (kept short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64013dc8-4cb1-4e06-8093-e9905edc7bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALOGUE_SYSTEM = \"\"\"You write snappy, character-driven dialogue.\n",
    "Output format:\n",
    "SPEAKER: line\n",
    "  (stage direction / subtext)\n",
    "No narration; only dialogue and concise stage directions.\n",
    "Honor each character's objective and emotion. Keep lines short (≤18 words).\n",
    "\"\"\"\n",
    "\n",
    "def generate_dialogue(characters: List[Dict[str, str]],\n",
    "                      scene_goal: str,\n",
    "                      conflict_axis: str,\n",
    "                      turns: int = 10) -> str:\n",
    "    roster = \"\\n\".join(f\"- {c['name']} ({c['role']}), objective: {c['objective']}, emotion: {c['emotion']}\" for c in characters)\n",
    "    user = f\"\"\"Characters:\n",
    "{roster}\n",
    "\n",
    "Scene goal: {scene_goal}\n",
    "Primary conflict axis: {conflict_axis}\n",
    "Turn budget: {turns}\n",
    "\n",
    "Write dialogue now.\"\"\"\n",
    "    prompt = f\"<|system|>\\n{DIALOGUE_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=500, temperature=0.9, top_p=0.92, repetition_penalty=1.06))\n",
    "\n",
    "# Example:\n",
    "# chars = [\n",
    "#     {\"name\":\"Mira\",\"role\":\"protagonist\",\"objective\":\"convince Arjun to leave\",\"emotion\":\"wary\"},\n",
    "#     {\"name\":\"Arjun\",\"role\":\"foil\",\"objective\":\"stall for time\",\"emotion\":\"deflective\"},\n",
    "# ]\n",
    "# dlg = generate_dialogue(chars, \"Mira tries to get Arjun out before the storm hits.\", \"trust vs control\", turns=8)\n",
    "# print(dlg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a92d5d-7efd-4f9b-adf7-46bc973aacdf",
   "metadata": {},
   "source": [
    "## 5) Style Transfer (tone) with a two-pass content-preservation plan\n",
    "\n",
    "Single-shot “rewrite in style X” often drifts. We mitigate with content planning:\n",
    "\n",
    "Extract a content plan (facts, plot beats, entities) in JSON.\n",
    "\n",
    "Rewrite to a target style/tone while anchoring to the plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ddb55eb-f04b-41b4-906b-8330c04a70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_PLAN_SYSTEM = \"\"\"Extract a content plan JSON with keys:\n",
    "- entities: [{name, type, attributes?}]\n",
    "- events: [{order, summary}]\n",
    "- constraints: [{kind, text}]  # e.g., must-keep metaphors, lexical items\n",
    "Output only JSON (no markdown).\n",
    "\"\"\"\n",
    "\n",
    "def extract_content_plan(text: str) -> Dict[str, Any]:\n",
    "    user = f\"Extract the content plan from this passage:\\n{text}\\n\"\n",
    "    prompt = f\"<|system|>\\n{CONTENT_PLAN_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    raw = generate(prompt, DecodeCfg(max_new_tokens=500, temperature=0.3, top_p=0.9, repetition_penalty=1.01))\n",
    "    raw = re.sub(r\"^```(?:json)?|```$\", \"\", raw, flags=re.IGNORECASE|re.MULTILINE).strip()\n",
    "    plan = json.loads(re.search(r\"\\{.*\\}\", raw, flags=re.DOTALL).group(0))\n",
    "    return plan\n",
    "\n",
    "STYLE_TRANSFER_SYSTEM = \"\"\"You perform style transfer while preserving content.\n",
    "Rules:\n",
    "- Faithfully preserve entities and event order from the plan.\n",
    "- Apply the requested tone/style features.\n",
    "- Avoid archaic words unless asked.\n",
    "- Keep output length within ±15% of the input length unless asked.\n",
    "\"\"\"\n",
    "\n",
    "def style_transfer(text: str, target_style: str) -> str:\n",
    "    plan = extract_content_plan(text)\n",
    "    plan_json = json.dumps(plan, ensure_ascii=False, indent=2)\n",
    "    user = f\"\"\"Target style/tone: {target_style}\n",
    "\n",
    "Content plan (must preserve):\n",
    "{plan_json}\n",
    "\n",
    "Source passage:\n",
    "{text}\n",
    "\n",
    "Rewrite now in the target style while preserving facts and ordering.\"\"\"\n",
    "    prompt = f\"<|system|>\\n{STYLE_TRANSFER_SYSTEM}\\n<|user|>\\n{user}\\n<|assistant|>\\n\"\n",
    "    return generate(prompt, DecodeCfg(max_new_tokens=700, temperature=0.7, top_p=0.9, repetition_penalty=1.02))\n",
    "\n",
    "# Example:\n",
    "# src = \"Mira stepped onto the flooded platform, the loudspeakers coughing warnings as wind bent the halyard.\"\n",
    "# print(style_transfer(src, \"noir, clipped sentences, wry subtext, contemporary diction\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943ae8d-6ee4-44e9-88e4-acd6ff04372f",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774aa0ba-c621-4da4-a449-1e7a17e027dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPANDED PROMPT ===\n",
      " You are a narrative development assistant.\n",
      "Expand terse story prompts into a structured creative brief with:\n",
      "- Premise (1–2 sentences)\n",
      "- World/Setting (specific time/place, social context)\n",
      "- Themes (3 bullets)\n",
      "- Protagonist & Goal (bio + objective)\n",
      "- Antagonistic Force (person/system/internal)\n",
      "- Stakes (why it matters)\n",
      "- Constraints (tone, POV, target length)\n",
      "- 5-Beat Outline (Beat #: heading + 1–2 lines)\n",
      "Return clean Markdown with headings and bullets.\n",
      "\n",
      " Seed prompt: A shy linguistics student discovers a dead language can summon storms.\n",
      "\n",
      "Produce the structured expansion now.\n",
      " # Creative Brief: \"Whispers of the Storm\"\n",
      "\n",
      "## Premise\n",
      "A reserved college student uncovers an ancient text that reveals a forgotten dialect's power to control weather patterns.\n",
      "\n",
      "## World/Setting\n",
      "- **Time Period**: Late 19th century\n",
      "- **Place**: Oxford University, England\n",
      "- **Social Context**: Victorian era - Science is making rapid advancements but superstitions about the arcane persist.\n",
      "\n",
      "## Themes\n",
      "- The intertwining of nature and knowledge\n",
      "- The conflict between science and mythology\n",
      "- Self-discovery through hidden history\n",
      "\n",
      "## Protagonist & Goal\n",
      "- **Protagonist Name**: Evelyn Arden\n",
      "- **Background**: Linguisti \n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "unexpected content after document: line 118 column 1 (char 2102)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m, in \u001b[0;36mscene_json_from_outline\u001b[0;34m(expanded_outline_md, beat_index)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43morjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SceneSchema\u001b[38;5;241m.\u001b[39mmodel_validate(data)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: unexpected character: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m expanded \u001b[38;5;241m=\u001b[39m expand_prompt(seed)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== EXPANDED PROMPT ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, expanded[:\u001b[38;5;241m1200\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m scene_plan \u001b[38;5;241m=\u001b[39m \u001b[43mscene_json_from_outline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeat_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== SCENE JSON ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(scene_plan\u001b[38;5;241m.\u001b[39mmodel_dump(), ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[9], line 52\u001b[0m, in \u001b[0;36mscene_json_from_outline\u001b[0;34m(expanded_outline_md, beat_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not return JSON.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext[:\u001b[38;5;241m800\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43morjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SceneSchema\u001b[38;5;241m.\u001b[39mmodel_validate(data)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m ve:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: unexpected content after document: line 118 column 1 (char 2102)"
     ]
    }
   ],
   "source": [
    "seed = \"A shy linguistics student discovers a dead language can summon storms.\"\n",
    "expanded = expand_prompt(seed)\n",
    "print(\"=== EXPANDED PROMPT ===\\n\", expanded[:1200], \"\\n\")\n",
    "\n",
    "scene_plan = scene_json_from_outline(expanded, beat_index=1)\n",
    "print(\"=== SCENE JSON ===\")\n",
    "print(json.dumps(scene_plan.model_dump(), ensure_ascii=False, indent=2))\n",
    "\n",
    "scene_text = render_scene_prose(scene_plan, target_len=180)\n",
    "print(\"\\n=== SCENE PROSE ===\\n\", scene_text, \"\\n\")\n",
    "\n",
    "chars = [\n",
    "    {\"name\":\"Mira\",\"role\":\"protagonist\",\"objective\":\"test the storm-chant safely\",\"emotion\":\"guarded\"},\n",
    "    {\"name\":\"Arjun\",\"role\":\"mentor\",\"objective\":\"discourage reckless use\",\"emotion\":\"anxious\"}\n",
    "]\n",
    "dialogue = generate_dialogue(chars,\n",
    "                             scene_goal=\"Negotiate boundaries for trying the chant on the pier.\",\n",
    "                             conflict_axis=\"curiosity vs caution\",\n",
    "                             turns=8)\n",
    "print(\"=== DIALOGUE ===\\n\", dialogue, \"\\n\")\n",
    "\n",
    "styled = style_transfer(scene_text, \"magical realism with lightly lyrical cadence, restrained metaphors, present tense\")\n",
    "print(\"=== STYLE-TRANSFERRED ===\\n\", styled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691edb5-9451-4ead-a64f-4aeadff416d3",
   "metadata": {},
   "source": [
    "## Notes, tips, and swaps\n",
    "\n",
    "### Model swaps:\n",
    "\n",
    "Small & easy: microsoft/Phi-3-mini-4k-instruct, Qwen/Qwen2.5-3B-Instruct.\n",
    "\n",
    "Mid/heavier: meta-llama/Meta-Llama-3.1-8B-Instruct.\n",
    "\n",
    "If you prefer GGUF models via llama-cpp-python, load with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456c13b-cc8e-4c81-bf54-90d1853dd4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
